import os

import streamlit as st
from dotenv import load_dotenv
from langchain.chains import create_sql_query_chain
from langchain.prompts import PromptTemplate
from langchain_community.utilities import SQLDatabase
from langchain_ollama.chat_models import ChatOllama
from langchain_openai import ChatOpenAI

from util import clean_sql_response, convert_result_to_df

# è®€å– .env è®Šæ•¸
load_dotenv()


# å–å¾—è³‡æ–™åº«é€£ç·šå­—ä¸²
DB_URL = os.getenv("DB_URL")
if not DB_URL:
    raise Exception("æœªåœ¨ .env æª”æ¡ˆä¸­æ‰¾åˆ° DB_URL")

MAX_RETRIES = 3  # æœ€å¤šé‡è©¦æ¬¡æ•¸

# é€£æ¥è³‡æ–™åº«
db = SQLDatabase.from_uri(DB_URL)

# å–å¾— `table_info`
table_info = db.get_table_info()

# åˆå§‹åŒ– LLM æ¨¡å‹
LLM_TYPE = os.getenv("LLM_TYPE", "OPENAI")  # é»˜èªç‚º OPENAI
llm = None

if LLM_TYPE == "OPENAI":
    OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
    OPENAI_MODEL = os.getenv("OPENAI_MODEL")

    if not OPENAI_API_KEY:
        raise Exception("æœªåœ¨ .env æª”æ¡ˆä¸­æ‰¾åˆ° OPENAI_API_KEYã€‚")
    if not OPENAI_MODEL:
        raise Exception("æœªåœ¨ .env æª”æ¡ˆä¸­æ‰¾åˆ° OPENAI_MODEL")

    llm = ChatOpenAI(model=OPENAI_MODEL, temperature=0, api_key=OPENAI_API_KEY)

elif LLM_TYPE == "OLLAMA":
    OLLAMA_URL = os.getenv("OLLAMA_URL")
    OLLAMA_MODEL = os.getenv("OLLAMA_MODEL")

    if not OLLAMA_URL:
        raise Exception("æœªåœ¨ .env æª”æ¡ˆä¸­æ‰¾åˆ° OLLAMA_URL")
    if not OLLAMA_MODEL:
        raise Exception("æœªåœ¨ .env æª”æ¡ˆä¸­æ‰¾åˆ° OLLAMA_MODEL")

    llm = ChatOllama(model=OLLAMA_MODEL, base_url=OLLAMA_URL)

else:
    raise Exception(f"æœªæ”¯æ´çš„ LLM_TYPE: {LLM_TYPE}")


# è®€å– `./prompts/` å…§æ‰€æœ‰ `.txt` æª”æ¡ˆ
def load_context_from_folder(folder_path="./prompts"):
    context = ""
    for filename in os.listdir(folder_path):
        if filename.endswith(".txt"):
            with open(os.path.join(folder_path, filename), "r", encoding="utf-8") as file:
                context += file.read() + "\n\n"
    return context.strip()


# è®€å– Context
context_text = load_context_from_folder()

# è‡ªè¨‚ Promptï¼ŒåŒ…å« `context_text`
prompt = PromptTemplate.from_template(
    f"""
    {context_text}
    
    ä½ æ˜¯ä¸€å€‹ SQL ç”Ÿæˆå™¨ï¼Œè«‹åŸºæ–¼ä»¥ä¸‹çš„ `table_info` è³‡è¨Šç”Ÿæˆä¸€å€‹ SQL æŸ¥è©¢ï¼š
    
    - `table_info`: {{table_info}}
    - ä½¿ç”¨è€…çš„å•é¡Œ: {{input}}
    - æ¯æ¬¡ç²å–è³‡æ–™æ•¸é‡: {{top_k}}

    è«‹è¼¸å‡ºå®Œæ•´çš„ SQL æŸ¥è©¢ï¼Œä¸è¦åŒ…å«ä»»ä½•è§£é‡‹æ–‡å­—ã€‚
    """
)

# å‰µå»º SQL æŸ¥è©¢éˆ
chain = create_sql_query_chain(llm, db, prompt=prompt)

# Streamlit é é¢è¨­å®š
st.set_page_config(page_title="SQL æŸ¥è©¢ç”Ÿæˆå™¨", page_icon="ğŸ’¬", layout="wide")

# é é¢æ¨™é¡Œ
st.title("SQL æŸ¥è©¢ç”Ÿæˆå™¨ ğŸ’¬")


# ä½¿ç”¨è€…è¼¸å…¥
user_input = st.chat_input("è«‹è¼¸å…¥æ‚¨çš„å•é¡Œ...")

if user_input:

    # é¡¯ç¤ºä½¿ç”¨è€…è¼¸å…¥
    with st.chat_message("user"):
        st.markdown(user_input)

    sql_query = None
    query_result = None

    for retry in range(1, MAX_RETRIES + 1):
        try:
            # ç”Ÿæˆ SQL æŸ¥è©¢
            sql_query = chain.invoke({
                "question": user_input,
                "table_info": table_info,
                "top_k": 20
            })

            # æ¸…ç† SQL æŸ¥è©¢å­—ä¸²
            sql_query = clean_sql_response(sql_query)

            # ç›´æ¥ç”¨ LangChain å…§å»ºçš„ db.run() åŸ·è¡Œ SQL æŸ¥è©¢
            query_result = db.run(sql_query, include_columns=True)

            # å¦‚æœåŸ·è¡ŒæˆåŠŸï¼Œç›´æ¥è·³å‡º retry è¿´åœˆ
            break

        except Exception as e:
            if retry < MAX_RETRIES:
                with st.chat_message("assistant"):
                    st.markdown(f"âš ï¸ SQL åŸ·è¡Œå¤±æ•—ï¼š`{sql_query}`ï¼Œæ­£åœ¨é‡æ–°å˜—è©¦ ({retry}/{MAX_RETRIES})...")
            else:
                with st.chat_message("assistant"):
                    st.markdown(f"âŒ SQL åŸ·è¡Œå¤±æ•—ï¼š{e}")

                # ç§»é™¤éŒ¯èª¤çš„ SQL èªæ³•
                sql_query = None
                break

    if sql_query:

        with st.chat_message("assistant"):
            st.markdown(f"**ç”Ÿæˆçš„ SQL æŸ¥è©¢ï¼š**\n```sql\n{sql_query}\n```")

        try:
            # å°‡æŸ¥è©¢çµæœè½‰æ›æˆè¡¨æ ¼
            result_df = convert_result_to_df(query_result)

            # é¡¯ç¤ºæŸ¥è©¢çµæœ
            if not result_df.empty:
                with st.chat_message("assistant"):
                    st.markdown(f"âœ… æŸ¥è©¢æˆåŠŸï¼Œçµæœå¦‚ä¸‹ï¼š")
                with st.chat_message("table"):
                    st.dataframe(result_df)
            else:
                with st.chat_message("table"):
                    st.markdown(f"âš ï¸ æ²’æœ‰æŸ¥è©¢çµæœã€‚")

        except Exception as e:
            with st.chat_message("table"):
                st.markdown(f"âŒ çµæœè™•ç†éŒ¯èª¤ï¼š{e}")
